import numpy as np
from sklearn.metrics import mean_absolute_error

# Mini-Batch Gradient Descent function
def gradient_descent(X, y, learning_rate=0.01, batch_size=16, epochs=100):
    m, n = X.shape
    theta = np.random.randn(n, 1)  # random initialization

    for epoch in range(epochs):
        shuffled_indices = np.random.permutation(m)
        X_shuffled = X[shuffled_indices]
        y_shuffled = y[shuffled_indices]

        # TODO: Update theta for each batch
        for i in range(0, m, batch_size):
            xi = X_shuffled[i:i + batch_size]
            yi = y_shuffled[i:i + batch_size]
            gradients = 2 / batch_size * xi.T @ (xi @ theta - yi)
            theta = theta - learning_rate * gradients

    return theta

# Prepare sample data as per the lesson
X = np.random.rand(100, 3)
y = 5 * X[:, 0] - 3 * X[:, 1] + 2 * X[:, 2] + np.random.randn(100, 1)  # Example linear regression problem

# Perform Mini-Batch Gradient Descent
theta = gradient_descent(X, y)

# Obtain predictions using the optimized parameters
predictions = X.dot(theta)

# Calculate Mean Absolute Error (MAE) to evaluate the model
mae = mean_absolute_error(y, predictions)
print(f"MAE: {mae}")
